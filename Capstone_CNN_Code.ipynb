{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required imports for the following model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For general functionality and model triaing, tuning, testing and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import import_ipynb\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models, losses\n",
    "from sklearn.model_selection import train_test_split\n",
    "import swifter\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# For preprocessing\n",
    "import ipynb\n",
    "from ipynb.fs.full.capstone_functions import *\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from sentinelhub import MimeType, CRS, BBox, SentinelHubRequest, SentinelHubDownloadClient, \\\n",
    "    DataCollection, bbox_to_dimensions, DownloadRequest, SentinelHubBatch\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sentinelhub import SHConfig\n",
    "from datetime import datetime\n",
    "import math\n",
    "import re, ast # Do I need this?\n",
    "import struct # Do I need this?\n",
    "import csv\n",
    "import gdal\n",
    "import fiona\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Import Code to Preprocess, Extract, and Save Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This section Implements the preprocessing functions created and imported from captsone_funtions.ipynb. For more detailed explanations of the preprocessing pipeline please see capstone_funtions.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment the lights at night tiff down to a specific shape file.\n",
    "cut_raster_with_shape('/Users/zaneheald/Desktop/Capstone/201912/201912_avg.tif',# Lights at night tiff (for a specific 1/6 qudrant of the globe)\n",
    "                      '/Users/zaneheald/Desktop/Capstone/bangladesh_1/gadm36_BGD_0.shp', # Shape file of the desired country or region (bangladesh)\n",
    "                      'bangladesh_raster_final.tif' # Name of the tiff file to save the clipped lights at night tiff to.\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the clipped nights at light tiff file to a csv file\n",
    "data_file = raster_to_csv('/Users/zaneheald/Desktop/Capstone/bangladesh_raster_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the CSV data extracted above and apply the necesary preporcessing funtions.\n",
    "data = pd.read_csv(data_file, sep = \" \", header = None)\n",
    "country = pre_process_csv(data)\n",
    "country_no_outliers = remove_outliers(country,3)\n",
    "country_agg = agg_radiance(country_no_outliers, 1)\n",
    "country_boxes = get_boxes(country_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using your unique client id and seceret key from the sentinel hub api interface, apply the image extraction process defined in capstone_funtions.ipynb\n",
    "client_id = ''\n",
    "secret = ''\n",
    "\n",
    "mapped_boxes = map_sentinel_images (country_boxes,client_id, secret)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map images to radiance levels and save these photos to a directory with lat, lon and radiance as the jpeg name.\n",
    "label_image = map_image_to_labels(country_agg, mapped_boxes)\n",
    "label_image['image'] = label_image.apply(lambda row: extract_image(row), axis = 1)\n",
    "save_photos(class_image, 'final_final_final_bangladesh_images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Read Images and Implement Final Prepocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the images, lat, lon, and radiance to a df from a directory.\n",
    "path = '/Users/zaneheald/Desktop/Capstone/final_final_final_bangladesh_images' #directory containing images (saved above)\n",
    "data = photo_df(path = path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the Radiance Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "data_scaled = data.copy()\n",
    "data_scaled.Radiance = scaler.fit_transform(np.array(data.Radiance).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of Radiance Values\n",
    "plt.scatter(range(len(data)),data_scaled.Radiance, color = 'Red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Prepare Data for Model Creation - TensorFlow Data Set Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess(path, label):\n",
    "    img_height, img_width = 128, 128\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_image(image, channels=3,expand_animations = False)\n",
    "    image = tf.image.resize(image, [img_height, img_width])\n",
    "    image /= 255.0\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tensor_ds (df,n_epochs,batch_size):\n",
    "    \n",
    "    tf.random.set_seed(12345)\n",
    "    \n",
    "    ds_files_labels = tf.data.Dataset.from_tensor_slices(\n",
    "    (df['image_label'],df['Radiance']))\n",
    "    \n",
    "    ds_images_labels = ds_files_labels.map(load_and_preprocess) #.shuffle(buffer_size = len(df) - 1)\n",
    "    \n",
    "    split_size = int(len(ds_images_labels)*.8) # 80/20 train test split\n",
    "    \n",
    "    val_size = int(len(ds_images_labels)*.1) # 10% of train goes to validataion\n",
    "    ds_train = ds_images_labels.take(split_size)\n",
    "    ds_test = ds_images_labels.skip(split_size)\n",
    "    ds_val = ds_train.take(val_size)\n",
    "    ds_train = ds_train.skip(val_size)\n",
    "        \n",
    "    buffer_size = len(ds_train)\n",
    "    \n",
    "    ds_train_sh = ds_train.shuffle(buffer_size=buffer_size)\n",
    "    ds_train_sh = ds_train_sh.batch(batch_size)\n",
    "    ds_train_sh = ds_train_sh.repeat(n_epochs)\n",
    "    \n",
    "    ds_test = ds_test.batch(batch_size= batch_size)\n",
    "    \n",
    "    ds_val = ds_val.batch(batch_size = batch_size)\n",
    "    \n",
    "    return (ds_train_sh, ds_test, ds_val)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Hyperparameers\n",
    "n_epochs = 100\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_sh, ds_test, ds_val = to_tensor_ds(data_scaled, n_epochs, batch_size)\n",
    "steps = np.ceil(len(ds_train_sh) / batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Simple CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To compare the value of transfer learning in solving this problem the following CNN has been designed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_shape=(128, 128, 3)\n",
    "cnn_simple=models.Sequential()\n",
    "cnn_simple.add(layers.Conv2D(16, kernel_size=(5,5), padding=\"same\", activation='relu', input_shape=Input_shape))\n",
    "cnn_simple.add(layers.MaxPooling2D((2,2)))\n",
    "cnn_simple.add(layers.Conv2D(32, kernel_size=(3,3), padding=\"same\", activation='relu', input_shape=Input_shape))\n",
    "cnn_simple.add(layers.MaxPooling2D((4,4)))\n",
    "cnn_simple.add(layers.Flatten())\n",
    "cnn_simple.add(layers.Dense(32, activation='relu'))\n",
    "cnn_simple.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "cnn_simple.summary()\n",
    "\n",
    "cnn_simple.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement Early Stopping to save computational time (as this is a simple model without transfer learning)\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the simple model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history_simple = cnn_simple.fit(ds_train_sh,\n",
    "                    epochs=n_epochs,\n",
    "                    steps_per_epoch = steps,\n",
    "                    validation_data=ds_val,\n",
    "                    callbacks=[es],\n",
    "                    verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Simple Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cnn_simple.evaluate(ds_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cnn_simple.predict(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_actual = []\n",
    "for item in ds_test:\n",
    "    for i in item[1].numpy():\n",
    "        test_actual.append(i)\n",
    "\n",
    "mean_squared_error(test_actual,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Simple Model's Outcome (Pred vs Actual, MSE, and Loss Curve) to Evaluate it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = plt.scatter(range(len(pred)),pred)\n",
    "actual = plt.scatter(range(len(pred)),test_actual, color = 'Red', alpha = .08)\n",
    "plt.legend((predicted,actual),\n",
    "           ('Predicted', 'Actual_Test_Vale'),\n",
    "           scatterpoints=1,\n",
    "           loc='upper right',\n",
    "           fontsize=8)\n",
    "plt.title('Predicted vs Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history_simple.history['mae']\n",
    "val_acc = history_simple.history['val_mae']\n",
    "\n",
    "loss = history_simple.history['loss']\n",
    "val_loss = history_simple.history['val_loss']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training MAE')\n",
    "plt.plot(val_acc, label='Validation MAE')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('MAE')\n",
    "plt.ylim([0,.2])\n",
    "plt.title('Training and Validation MAE')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Mean Square Error')\n",
    "plt.ylim([0,.2])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the requirements / import the transfer learning model. (This implements the Mobile Net Version 2 Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (128, 128)\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "base_model.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Model Creation w/ Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design a model and implement transfer learning with Mobile Net to improve performance as compared to the simple model. (This model has been iteratively tuned for best performance as measured by MSE):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1 = layers.Conv2D(32, kernel_size=(5,5), padding=\"same\", activation='relu', input_shape=IMG_SHAPE \n",
    "                        ,bias_regularizer=tf.keras.regularizers.l1(0.001))\n",
    "pool_1 = layers.MaxPooling2D((2,2))\n",
    "dropout = layers.Dropout(.1, input_shape=IMG_SHAPE)\n",
    "layer_2 = layers.Conv2D(64, kernel_size=(3,3), padding=\"same\", activation='relu', input_shape=IMG_SHAPE\n",
    "                       ,bias_regularizer=tf.keras.regularizers.l1(0.01))\n",
    "pool_2 = layers.MaxPooling2D((2,2))\n",
    "layer_3 = layers.Conv2D(128, kernel_size=(2,2), padding=\"same\", activation='relu', input_shape=IMG_SHAPE\n",
    "                       ,bias_regularizer=tf.keras.regularizers.l1(0.01))\n",
    "pool_3 = layers.MaxPooling2D((1,1))\n",
    "layer_4 = layers.Conv2D(256, kernel_size=(2,2), padding=\"same\", activation='relu', input_shape=IMG_SHAPE\n",
    "                       ,bias_regularizer=tf.keras.regularizers.l1(0.01))\n",
    "pool_4 = layers.MaxPooling2D((1,1))\n",
    "flatten = layers.Flatten()\n",
    "dense_1 = layers.Dense(256, activation='relu', bias_regularizer=tf.keras.regularizers.l1(0.01))\n",
    "prediction_layer = layers.Dense(1, activation='linear')\n",
    "\n",
    "\n",
    "inputs = tf.keras.Input(shape=(128, 128, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = layer_1(x)\n",
    "x = pool_1(x)\n",
    "x = dropout(x)\n",
    "x = layer_2(x)\n",
    "x = pool_2(x)\n",
    "x = layer_3(x)\n",
    "x = pool_3(x)\n",
    "x = layer_4(x)\n",
    "x = pool_4(x)\n",
    "x = flatten(x)\n",
    "x = dense_1(x)\n",
    "outputs = prediction_layer(x)\n",
    "cnn_model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Transfer Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history_sh = cnn_model.fit(ds_train_sh,\n",
    "                    epochs=n_epochs,\n",
    "                    steps_per_epoch = steps,\n",
    "                    validation_data=ds_val,\n",
    "                    callbacks=[es],\n",
    "                    verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the performance of the Transfer Learning Model (numerically and visually) - These metrics were used in interatively tuneing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cnn_model.evaluate(ds_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cnn_model.predict(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled.Radiance.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_actual = []\n",
    "for item in ds_test:\n",
    "    for i in item[1].numpy():\n",
    "        test_actual.append(i)\n",
    "\n",
    "mean_squared_error(test_actual,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Predicted vs Actual of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = plt.scatter(range(len(pred)),pred)\n",
    "plt.title('Predicted vs Actual)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = plt.scatter(range(len(pred)),pred)\n",
    "actual = plt.scatter(range(len(pred)),test_actual, color = 'Red', alpha = .08)\n",
    "plt.legend((predicted,actual),\n",
    "           ('Predicted', 'Actual_Test_Vale'),\n",
    "           scatterpoints=1,\n",
    "           loc='upper right',\n",
    "           fontsize=8)\n",
    "plt.title('Predicted vs Actual (10,000 Data Set Scaled)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Evaluate based on real numbers (rather than scaled numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_real = scaler.inverse_transform(pred.reshape(-1, 1))\n",
    "test_real = scaler.inverse_transform(np.array(test_actual).reshape(-1, 1))\n",
    "\n",
    "mean_squared_error(test_real,pred_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = plt.scatter(range(len(pred_real)),pred_real)\n",
    "plt.title('Predicted vs Actual)')# (10,000 Data Set w/Transfer Learning)')\n",
    "plt.show()\n",
    "\n",
    "predicted = plt.scatter(range(len(pred_real)),pred_real)\n",
    "actual = plt.scatter(range(len(pred_real)),test_real, color = 'Red', alpha = .08)\n",
    "plt.legend((predicted,actual),\n",
    "           ('Predicted', 'Actual_Test_Vale'),\n",
    "           scatterpoints=1,\n",
    "           loc='upper right',\n",
    "           fontsize=8)\n",
    "plt.title('Predicted vs Actual (10,000 Data Set w/Transfer Learning)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate based on urban vs rural areas - The model tends to perform better on rural areas than urban areas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaled results:\n",
    "above_1 = []\n",
    "above_1_pred = []\n",
    "below_1 = []\n",
    "below_1_pred = []\n",
    "for i, val in enumerate(test_actual):\n",
    "    if val > .4:\n",
    "        above_1.append(val)\n",
    "        above_1_pred.append(pred_ar[i])\n",
    "    else:\n",
    "        below_1.append(val)\n",
    "        below_1_pred.append(pred_ar[i])\n",
    "\n",
    "        \n",
    "        \n",
    "bright_mse = mean_squared_error(above_1,above_1_pred)\n",
    "print(math.sqrt(bright_mse))\n",
    "\n",
    "dim_mse = mean_squared_error(below_1,below_1_pred)\n",
    "print(math.sqrt(dim_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual unscaled numbers\n",
    "above_1 = []\n",
    "above_1_pred = []\n",
    "below_1 = []\n",
    "below_1_pred = []\n",
    "for i, val in enumerate(test_real):\n",
    "    if val > 2:\n",
    "        above_1.append(val)\n",
    "        above_1_pred.append(pred_real[i])\n",
    "    else:\n",
    "        below_1.append(val)\n",
    "        below_1_pred.append(pred_real[i])\n",
    "\n",
    "# MSE of predictions above radiance of 1\n",
    "bright_mse = mean_squared_error(above_1,above_1_pred)\n",
    "math.sqrt(bright_mse)\n",
    "\n",
    "# MSE of predictions below 1\n",
    "dim_mse = mean_squared_error(below_1,below_1_pred)\n",
    "math.sqrt(dim_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the MSE and Loss of the model in order to evaluate its utility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph the loss and MAE\n",
    "acc = history_sh.history['mae']\n",
    "val_acc = history_sh.history['val_mae']\n",
    "\n",
    "loss = history_sh.history['loss']\n",
    "val_loss = history_sh.history['val_loss']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training MAE')\n",
    "plt.plot(val_acc, label='Validation MAE')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('MAE')\n",
    "plt.ylim([0,.2])\n",
    "plt.title('Training and Validation MAE')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Mean Square Error')\n",
    "plt.ylim([0,.2])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Creation \n",
    "https://towardsdatascience.com/a-guide-to-an-efficient-way-to-build-neural-network-architectures-part-ii-hyper-parameter-42efca01e5d7\n",
    "\n",
    "https://towardsdatascience.com/ultimate-guide-to-input-shape-and-model-complexity-in-neural-networks-ae665c728f4b\n",
    "\n",
    "https://www.tensorflow.org/tutorials/images/cnn\n",
    "\n",
    "https://towardsdatascience.com/guide-to-coding-a-custom-convolutional-neural-network-in-tensorflow-bec694e36ad3\n",
    "\n",
    "###### Pooling layers\n",
    "https://machinelearningmastery.com/pooling-layers-for-convolutional-neural-networks/ \n",
    "\n",
    "### Transfer learning\n",
    "https://www.tensorflow.org/tutorials/images/transfer_learning\n",
    "\n",
    "https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a\n",
    "\n",
    "\n",
    "### Class Imbalance\n",
    "https://datascience.stackexchange.com/questions/56447/poor-performance-of-regression-model-for-imbalanced-data\n",
    "\n",
    "https://www.aaai.org/Papers/Workshops/2000/WS-00-05/WS00-05-001.pdf\n",
    "\n",
    "\n",
    "### Batch, step, epoch\n",
    "https://medium.com/@elimu.michael9/understanding-epochs-and-batches-23120a04b3cb\n",
    "\n",
    "### Data Augmentation\n",
    "https://www.tensorflow.org/tutorials/images/data_augmentation\n",
    "\n",
    "### Youtube NN Explained\n",
    "https://www.youtube.com/watch?v=pHMzNW8Agq4\n",
    "\n",
    "### l1 vs l2 regularization\n",
    "https://stats.stackexchange.com/questions/383310/what-is-the-difference-between-kernel-bias-and-activity-regulizers-and-when-t\n",
    "\n",
    "https://www.machinecurve.com/index.php/2020/01/23/how-to-use-l1-l2-and-elastic-net-regularization-with-keras/\n",
    "\n",
    "### Fix NaN - Better result ideas\n",
    "https://stackoverflow.com/questions/37232782/nan-loss-when-training-regression-network\n",
    "\n",
    "### MSE vs MAE \n",
    "https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d\n",
    "\n",
    "### Adam tuning\n",
    "https://mlfromscratch.com/optimizers-explained/#momentum\n",
    "\n",
    "### CNN Cheat Sheet\n",
    "https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
